"""
Configuration for real cosmological datasets
Automatically generated by fetch_real_cosmology_data.sh
"""

import os
import numpy as np
import sys

# Get project directory
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(PROJECT_DIR, "data")

# Dataset file paths (UPDATE THESE IN YOUR MAIN CODE)
DATASET_PATHS = {
    # CMB
    'planck_tt': os.path.join(DATA_DIR, "planck", "planck_raw_TT.txt"),
    
    # BAO
    'boss_dr12': os.path.join(DATA_DIR, "bao", "boss_dr12_consensus.txt"),
    'eboss_lyalpha_bao': os.path.join(DATA_DIR, "bao", "eboss_lyalpha_bao.txt"),
    
    # Supernovae (REAL Pantheon+ with full covariance)
    'pantheon_plus': os.path.join(DATA_DIR, "sne", "pantheon_plus", "Pantheon+SH0ES.dat"),
    'pantheon_cov': os.path.join(DATA_DIR, "sne", "pantheon_plus", "Pantheon+SH0ES_STAT+SYS.cov"),
    'sh0es': os.path.join(DATA_DIR, "sne", "sh0es_2022.txt"),
    
    # Growth
    'rsd_growth': os.path.join(DATA_DIR, "growth", "rsd_measurements.txt"),
    
    # Lyman-alpha (REAL eBOSS data)
    'lyalpha_flux': os.path.join(DATA_DIR, "lyalpha", "eboss_lyalpha_REAL.dat"),
    
    # Reference
    'planck_params': os.path.join(DATA_DIR, "misc", "planck2018_params.txt"),
    'tensions': os.path.join(DATA_DIR, "misc", "cosmological_tensions.txt"),
}

def load_planck_tt():
    """Load Planck TT power spectrum"""
    path = DATASET_PATHS['planck_tt']
    if not os.path.exists(path):
        raise FileNotFoundError(f"Planck data not found: {path}")
    
    data = np.loadtxt(path)
    if data.shape[1] >= 3:
        return {
            'ell': data[:, 0],
            'Dl': data[:, 1],
            'Dl_err': data[:, 2],
            'bin_width': data[:, 3] if data.shape[1] > 3 else None,
            'source': 'Planck 2018 TT (binned)'
        }
    return None

def load_boss_bao():
    """Load BOSS DR12 BAO"""
    path = DATASET_PATHS['boss_dr12']
    if not os.path.exists(path):
        raise FileNotFoundError(f"BOSS BAO data not found: {path}")
    
    data = np.loadtxt(path)
    return {
        'z': data[:, 0],
        'DV_rd': data[:, 1],
        'DV_rd_err': data[:, 2],
        'DM_rd': data[:, 3] if data.shape[1] > 3 else None,
        'DM_rd_err': data[:, 4] if data.shape[1] > 4 else None,
        'source': 'BOSS DR12 Consensus BAO'
    }

def load_pantheon_plus():
    """Load Pantheon+ supernovae"""
    path = DATASET_PATHS['pantheon_plus']
    if not os.path.exists(path):
        raise FileNotFoundError(f"Pantheon+ data not found: {path}")
    
    data = np.loadtxt(path)
    return {
        'z': data[:, 0],
        'mu': data[:, 1],
        'mu_err': data[:, 2],
        'mu_sys': data[:, 3] if data.shape[1] > 3 else None,
        'source': 'Pantheon+ Compressed'
    }

def load_sh0es():
    """Load SH0ES H0 measurement"""
    path = DATASET_PATHS['sh0es']
    if not os.path.exists(path):
        raise FileNotFoundError(f"SH0ES data not found: {path}")
    
    data = np.loadtxt(path)
    return {
        'H0': data[0, 0],
        'H0_err': data[0, 1],
        'source': 'SH0ES 2022'
    }

def load_rsd_growth():
    """Load RSD growth measurements"""
    path = DATASET_PATHS['rsd_growth']
    if not os.path.exists(path):
        raise FileNotFoundError(f"RSD growth data not found: {path}")
    
    try:
        data = np.loadtxt(path, dtype=str)
        return {
            'z': data[:, 0].astype(float),
            'fsigma8': data[:, 1].astype(float),
            'fsigma8_err': data[:, 2].astype(float),
            'survey': data[:, 3] if data.shape[1] > 3 else None,
            'source': 'RSD Growth Compilation'
        }
    except:
        # Fallback to numeric-only
        data = np.loadtxt(path)
        return {
            'z': data[:, 0],
            'fsigma8': data[:, 1],
            'fsigma8_err': data[:, 2],
            'source': 'RSD Growth'
        }

def load_planck_params():
    """Load Planck 2018 reference parameters"""
    path = DATASET_PATHS['planck_params']
    if not os.path.exists(path):
        raise FileNotFoundError(f"Planck parameters not found: {path}")
    
    params = {}
    with open(path, 'r') as f:
        for line in f:
            if line.startswith('#') or not line.strip():
                continue
            parts = line.strip().split()
            if len(parts) >= 3:
                params[parts[0]] = {
                    'value': float(parts[1]),
                    'error': float(parts[2])
                }
    return params

def list_datasets():
    """List all available datasets with status"""
    print("Available datasets:")
    print("="*60)
    for name, path in DATASET_PATHS.items():
        if os.path.exists(path):
            size_kb = os.path.getsize(path) / 1024
            status = "✓"
        else:
            size_kb = 0
            status = "✗"
        print(f"{status} {name:25s} {size_kb:6.1f} KB")
    print("="*60)

def load_all_datasets():
    """Load all datasets and return dictionary"""
    datasets = {}
    
    try:
        datasets['planck_tt'] = load_planck_tt()
    except Exception as e:
        print(f"Warning loading Planck: {e}")
    
    try:
        datasets['boss_bao'] = load_boss_bao()
    except Exception as e:
        print(f"Warning loading BAO: {e}")
    
    try:
        datasets['pantheon'] = load_pantheon_plus()
    except Exception as e:
        print(f"Warning loading Pantheon+: {e}")
    
    try:
        datasets['sh0es'] = load_sh0es()
    except Exception as e:
        print(f"Warning loading SH0ES: {e}")
    
    try:
        datasets['growth'] = load_rsd_growth()
    except Exception as e:
        print(f"Warning loading growth: {e}")
    
    try:
        datasets['planck_params'] = load_planck_params()
    except Exception as e:
        print(f"Warning loading Planck params: {e}")
    
    return datasets

if __name__ == "__main__":
    list_datasets()
    print("\nSample data loading:")
    try:
        data = load_all_datasets()
        print(f"Loaded {len(data)} datasets")
    except Exception as e:
        print(f"Error: {e}")
